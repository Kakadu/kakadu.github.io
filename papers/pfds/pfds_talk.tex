\newif\ifanswers
%\answerstrue % comment out to hide answers
% hack from https://tex.stackexchange.com/questions/33576/conditional-typesetting-build

\documentclass[aspectratio=169
  , xcolor={svgnames}
  , hyperref={ colorlinks,citecolor=DeepPink4
             , linkcolor=DarkRed,urlcolor=DarkBlue}
  , russian
  ]{beamer}
\usetheme{CambridgeUS}
\beamertemplatenavigationsymbolsempty % remove navigation bar

\usefonttheme{professionalfonts}
\input{heading.tex}
\usepackage{tabulary}
\usepackage{verbatim}
% \usepackage{tabularx}  % for 'tabularx' environment
% \usepackage{ragged2e} % for \Centering macro
% \newcolumntype{C}{>{\Centering\arraybackslash}X}m
% sudo aptget install ttf-mscorefonts-installer
\defaultfontfeatures{Ligatures={TeX}} 
\setmainfont{Times New Roman}
\setsansfont{CMU Sans Serif}

\setmonofont[Scale=1.0,
    BoldFont=lmmonolt10-bold.otf,
    ItalicFont=lmmono10-italic.otf,
    BoldItalicFont=lmmonoproplt10-boldoblique.otf
]{lmmono9-regular.otf}

\newcommand{\term}[2]{\textit{#1} (#2)}

\usepackage[cache=true]{minted}
\usepackage{amsthm}

\newtheorem{remark}{\textbf{Замечание}}[section]
\newtheorem{hint}{\textbf{Указание разработчикам}}[section]

\newtheoremstyle{exerciseStyle1}
{}                % Space above
{}                % Space below
{}        % Theorem body font % (default is "\upshape")
{}                % Indent amount
{\bfseries}       % Theorem head font % (default is \mdseries)
{.}               % Punctuation after theorem head % default: no punctuation
{ }               % Space after theorem head
{}                % Theorem head spec
\theoremstyle{exerciseStyle1}
\newtheorem{exercise}{\textbf{Упражнение}}[section]


\deftranslation[to=russian]{Theorem}{Теорема}
\deftranslation[to=russian]{theorem}{теорема}

\usepackage{tikz}
\usetikzlibrary{trees}

%%%%%%%%%%%%%%%%%%
\makeatletter
\newenvironment{tabminted}{%
  \let\FV@ListVSpace\relax  
  \minted
}{%
  \endminted
  \unskip   
  \aftergroup\@tabmintedend
}
\newcommand*{\tabminted@finalstrut}[1]{%
  \ifdim\prevdepth>0pt
    \ifdim\dp#1>\prevdepth
      \vskip\dimexpr(\dp#1)-\prevdepth\relax
    \fi
  \else
    \vskip\dimexpr(\dp#1)\relax
  \fi
}
\newcommand*{\@tabmintedend}{%
  \let\@finalstrut\tabminted@finalstrut
}
\renewcommand{\cite}[1]{}
\makeatother


%%%%%%%%%%%%%%%%%%%%%5
\title[]{Чисто функциональные структуры данных}
\subtitle{С примерами кода на Haskell}
\author{Косарев Дмитрий }

\institute{матмех СПбГУ}

\date{\today}
 
\AtBeginSection[]
{
  \begin{frame}<beamer>
    \frametitle{Оглавление}
    \tableofcontents[currentsection,currentsubsection]
  \end{frame}
}

\newcommand{\verbatimfont}[1]{\def\verbatim@font{#1}}

\usepackage{verbatimbox}

\begin{document}
\maketitle

% For every picture that defines or uses external nodes, you'll have to
% apply the 'remember picture' style. To avoid some typing, we'll apply
% the style to all pictures.
\tikzstyle{every picture}+=[remember picture] 

% By default all math in TikZ nodes are set in inline mode. Change this to
% displaystyle so that we don't get small fractions.
\everymath{\displaystyle}

% Uncomment these lines for an automatically generated outline.
\begin{frame}{Оглавление}
  \tableofcontents
\end{frame}

\begin{frame}[fragile]{}
Мунк
\end{frame}

\section{Индуктивные типы данных}


\begin{frame}[fragile]{Сигнатура Stack. Реализация через встроенные списки}
\begin{minipage}{.48\textwidth}
\inputminted{haskell}{code/Stack.hs}
\end{minipage}
\begin{minipage}{.48\textwidth}
\inputminted{haskell}{code/ListStack.hs}
\end{minipage}
\end{frame}

\begin{frame}[fragile]{Сигнатура Stack. Реализация через новый тип данных}
\begin{minipage}{.48\textwidth}
  \inputminted{haskell}{code/Stack.hs}
\end{minipage}
\begin{minipage}{.48\textwidth}
  \inputminted{haskell}{code/CustomStack.hs}
\end{minipage}
\end{frame}

\begin{frame}[fragile]{Конкатенация списков}
\begin{minted}{haskell}
(++) :: Stack l => l a -> l a -> l a
\end{minted}
В императивной среде легко сделать за O(1), если хранить указатель на конец.
\end{frame}

\begin{frame}[fragile]{Конкатенация в императивной среде}
\begin{figure}[h]
%	\centering
	\input{figures/fig.2.4.before.tex}\par
	(до)\par
%	\vspace{0.5cm}
	\input{figures/fig.2.4.after.tex}\par
	(после)\par
%	\vspace{0.5cm}
	\caption{Выполнение xs concat ys в императивной среде. Эта операция уничтожает списки-аргументы xs и ys (их использовать больше нельзя)}
	\label{fig:2.4}
\end{figure}
\end{frame}


\begin{frame}[fragile]{Конкатенация в функциональной среде}
В функциональной среде мы не можем деструктивно модифицировать. Поэтому
\begin{itemize}
\item добавляем последний элемент первого списка ко второму
\item добавляем \emph{пред}последний элемент первого списка к резульату
\item и т.д.
\end{itemize}

\inputminted[firstline=43,lastline=47] {haskell}{code/Stacks.hs}
\end{frame}

\begin{frame}[fragile]{}
\inputminted[firstline=43,lastline=47] {haskell}{code/Stacks.hs}
Если нам доступно внутреннее представление, то можно написать более короткий идиоматичный код
\inputminted[firstline=50,lastline=51] {haskell}{code/Stacks.hs}
\end{frame}

\begin{frame}[fragile]{Конкатенация}
\begin{figure}[h]
	\centering
	\input{figures/fig.2.5.before.tex}\par
	(до)\par
	\vspace{0.5cm}
	\input{figures/fig.2.5.after.tex}\par
	(после)\par
	\vspace{0.5cm}
	\caption{Выполнение \texttt{zs = xs ++ ys} в функциональной среде. Заметим, что списки-аргументы \texttt{xs} и \texttt{ys} не затронуты операцией.
	}
	\label{fig:2.5}
\end{figure}
Несмотря на большой объем копирования, заметим, что второй список копировать не пришлось
\end{frame}

\begin{frame}[fragile]{Update}
\inputminted[firstline=61,lastline=64] {haskell}{code/Stacks.hs}
%Если нам доступно внутреннее представление, то можно написать более короткий идиоматичный код
Здесь мы не копируем весь список-аргумент.\\

Копировать приходится
только сам узел, подлежащий модификации (узел $i$) и узлы,
содержащие прямые или косвенные указатели на $i$. \\

Другими словами,
чтобы изменить один узел, мы копируем все узлы на пути от корня
к изменяемому. Все узлы, не находящиеся на этом пути, используются как
исходной, так и обновленной версиями. 
%На Рис.
%~\ref{fig:2.6} 
%показан
%результат изменения третьего узла в пятиэлементном списке: первые
%три узла копируются, а последние два используются совместно.
\end{frame}

\begin{frame}[fragile]{}
\begin{figure}[h]
	\centering
	\input{figures/fig.2.6.before.tex}\par
	(до)\par
	\vspace{0.5cm}
	\input{figures/fig.2.6.after.tex}\par
	(после)\par
	\vspace{0.5cm}	
	\caption{Выполнение \texttt{ys = update(xs, 2, 7)}. Обратите
		внимание на совместное использование структуры списками \texttt{xs} и \texttt{ys}.}
	\label{fig:2.6}
\end{figure}
\end{frame}

\begin{frame}[fragile]
\begin{remark}
	Такой стиль программирования очень сильно упрощается при наличии
	автоматической сборки мусора. Очень важно освободить память от тех
	копий, которые больше не нужны, но многочисленные совместно используемые
	узлы делают ручную сборку мусора нетривиальной задачей.
\end{remark}
\begin{exercise}\label{ex:2.1}
  Напишите функцию \texttt{suffixes} типа \mintinline{haskell}{[a] -> [a]}, которая принимает как
  аргумент список \texttt{xs} и возвращает список всех его
  суффиксов в убывающем порядке длины. Например,
  \begin{minted}{haskell}
  suffixes [1,2,3,4] = [[1,2,3,4],[2,3,4],[3,4],[4],[]]
  \end{minted}
  Покажите, что список суффиксов можно породить за время $O(n)$ и
  занять при этом $O(n)$ памяти.
\end{exercise}

\end{frame}

\section{Двоичные деревья поиска}
\label{sc:2.2}

\begin{frame}{Двоичные деревья поиска}
Если узел структуры содержит более одного указателя, оказываются
возможны более сложные сценарии совместного использования памяти. Хорошим примером
совместного использования такого вида служат \emph{двоичные деревья поиска}.

\inputminted[firstline=10, lastline=10] {haskell}{code/SearchTree.hs}

Двоичные деревья поиска~--- это двоичные деревья, в которых элементы
хранятся во внутренних узлах в \term{симметричном}{symmetric}
порядке, то есть, элемент в каждом узле больше любого элемента в
левом поддереве этого узла и меньше любого элемента в правом
поддереве.
\end{frame}

\begin{frame}[fragile]{}
\begin{figure}[h]
  \centering
  \inputminted[firstline=12, lastline=16] {haskell}{code/SearchTree.hs}
  \caption{Сигнатура для множеств.}
\label{fig:2.7}
\end{figure}

На Рис.~\ref{fig:2.7} показана минимальная сигнатура для множеств. Она
содержит значение <<пустое множество>>, а также функции добавления
нового элемента и проверки на членство.  В более практической
реализации, вероятно, будут присутствовать и многие другие функции,
например, для удаления элемента или перечисления всех элементов.
\end{frame}

\begin{frame}[fragile]{Функция member}
  \inputminted[firstline=22, lastline=25] {haskell}{code/SearchTree.hs}

Функция \texttt{member} ищет в дереве, сравнивая запрошенный
элемент с находящимся в корне дерева. Если запрошенный элемент меньше
корневого, мы рекурсивно ищем в левом поддереве.

 Если он больше,
рекурсивно ищем в правом поддереве. 

Наконец, в оставшемся случае
запрошенный элемент равен корневому, и мы возвращаем значение
<<истина>>. \\

Если мы когда-либо натыкаемся на пустое дерево, значит,
запрашиваемый элемент не является членом множества, и мы возвращаем
значение <<ложь>>. 
\end{frame}

\begin{frame}[fragile]{Функция insert}
\inputminted[firstline=27, lastline=30] {haskell}{code/SearchTree.hs}

Функция \lstinline{insert} проводит поиск в дереве по той же стратегии,
что и \lstinline{member}, но только по пути она копирует каждый
элемент.

Когда, наконец, оказывается достигнут пустой узел, он
заменяется на узел, содержащий новый элемент.
 
\end{frame}

\begin{frame}[fragile]{}
\begin{minipage}{.48\textwidth}
		\input{figures/fig.2.8.before.tex}\par
\end{minipage}
\begin{minipage}{.48\textwidth}
	\input{figures/fig.2.8.after.tex}
\end{minipage}
Выполнение \texttt{ys = insert("e", xs)}. 
%Как и прежде,
%обратите внимание на совместное использвание структуры деревьями \texttt{xs} и \texttt{ys}.

%Каждый скопированный узел использует одно из поддеревьев 
%совместно с исходным деревом; речь о том поддереве,
%которое не оказалось на пути поиска. 
Для большинства деревьев путь
поиска содержит лишь небольшую долю узлов в дереве. Громадное
большинство узлов находятся в совместно используемых поддеревьях.
\end{frame}

\begin{frame}
\begin{exercise}\textbf{Андерсон \cite{Andersson1991}}\label{ex:2.2}
  В худшем случае \lstinline{member} производит $2d$ сравнений, где
  $d$~--- глубина дерева. Перепишите ее так, чтобы она делала не более
  $d+1$ сравнений, сохраняя элемент, который \emph{может} оказаться
  равным запрашиваемому (например, последний элемент, для которого
  операция $<$ вернула значение <<истина>> или $\le$~--- <<ложь>>, и
  производя проверку на равенство только по достижении дна дерева.
\end{exercise}

\begin{exercise}\label{ex:2.3}
  Вставка уже существующего элемента в двоичное дерево поиска копирует
  весь путь поиска, хотя скопированные узлы неотличимы от
  исходных. Перепишите \lstinline{insert} так, чтобы она избегала
  копирования с помощью исключений. Установите только один обработчик
  исключений для всей операции поиска, а не по обработчику на итерацию.
\end{exercise}

\begin{exercise}\label{ex:2.4}
  Совместите улучшения из предыдущих двух упражнений, и получите
  версию \lstinline{insert}, которая не делает ненужного копирования и
  использует не более $d+1$ сравнений.
\end{exercise}
\end{frame}

\begin{frame}
\begin{exercise}\label{ex:2.5}
  Совместное использование может быть полезно и внутри одного объекта, не
  обязательно между двумя различными.  Например, если два поддерева
  одного дерева идентичны, их можно представить одним и тем же
  деревом.
  \begin{enumerate}
    \item Используя эту идею, напишите функцию \lstinline{complete} типа
    \mintinline{haskell}{Elem -> Int -> Tree}, такую, что
    \mintinline{haskell}{complete(x,d)} создает полное двоичное дерево глубины
    \lstinline{d}, где в каждом узле содержится \lstinline{x}.
    (Разумеется, такая функция бессмысленна для абстракции множества,
    но она может оказаться полезной для какой-либо другой абстракции,
    например, мультимножества.) Функция должна работать за время $O(d)$.
    \item Расширьте свою функцию, чтобы она строила сбалансированные
    деревья произвольного размера. Эти деревья не всегда будут полны,
    но они должны быть как можно более сбалансированными: для любого
    узла размеры поддеревьев должны различаться не более чем на
    единицу. Функция должна работать за время $O(\log n)$. (Подсказка:
    воспользуйтесь вспомогательной функцией \lstinline{create2},
    которая, получая размер $m$, создает пару деревьев~--- одно размера
    $m$, а другое размера $m+1$)
  \end{enumerate}
\end{exercise}
\end{frame}

\begin{frame}
\begin{exercise}\label{ex:2.6}
  Измените функтор \texttt{UnbalancedSet} так, чтобы он служил
  реализацией не множеств, а \term{конечных отображений}{finite maps}. На
  Рис.~\ref{fig:2.10} приведена минимальная сигнатура для конечных
  отображений. (Заметим, что исключение \texttt{NotFound} не
  является встроенным в Стандартный ML~--- Вам придется его определить
  самостоятельно. Это исключение можно было бы сделать частью
  сигнатуры \texttt{FiniteMap},  чтобы каждая реализация
  определяла собственное исключение \texttt{NotFound}, но удобнее,
  если все конечные отображения будут использовать одно и то же
  исключение.)
\end{exercise}

\end{frame}

\section{Левоориентированные кучи}

\begin{frame}[fragile]{}
Как правило, множества и конечные отображения поддерживают эффективный
доступ к произвольным элементам. Однако иногда требуется эффективный
доступ только к \emph{минимальному} элементу.  Структура данных,
поддерживающая такой режим доступа, называется \term{очередь с
приоритетами}{priority queue} или \term{куча}{heap}.

\inputminted[firstline=3, lastline=11] {haskell}{code/Heap.hs}
\end{frame}

\begin{frame}[fragile]{}
Часто кучи реализуются через деревья \term{с порядком
  кучи}{heap-ordered}, т.~е., в которых элемент при каждой вершине не
больше элементов в поддеревьях. При таком упорядочении минимальный
элемент дерева всегда находится в корне.\vspace{1cm}

Левоориентированные кучи \cite{Crane1972, Knuth1973a} представляют
собой двоичные деревья с порядком кучи, обладающие свойством
\term{левоориентированности}{leftist property}: ранг любого левого поддерева
не меньше ранга его сестринской правой вершины.  Ранг узла
определяется как длина его \term{правой периферии}{right spine}
(т.~е., самого правого пути от данного узла до пустого).  Простым
следствием свойства левоориентированности является то, что правая
периферия любого узла~--- кратчайший путь от него к пустому узлу.
\end{frame}

\begin{frame}[fragile]
Если у нас есть некоторая структура упорядоченных элементов
\mintinline{haskell}{Elem}, 
мы можем представить левоориентированные кучи как
двоичные деревья, снабженные информацией о ранге.
\begin{minted}{haskell}
datatype Heap = E | T Int  Elem.T  Heap Heap
\end{minted}

Заметим, что элементы правой периферии левоориентированной кучи (да и
любого дерева с порядком кучи) расположены в порядке возрастания.
Главная идея левоориентированной кучи заключается в том, что для
слияния двух куч достаточно слить их правые периферии как
упорядоченные списки, а затем вдоль полученного пути обменивать
местами поддеревья при вершинах, чтобы восстановить свойство
левоориентированности. 

\end{frame}

\begin{frame}[fragile]{}
\inputminted[firstline=23, lastline=26] {haskell}{code/Heap.hs}

где \lstinline!makeT!~--- вспомогательная функция, вычисляющая ранг
вершины \lstinline!T! и, если необходимо, меняющая местами ее
поддеревья.

\inputminted[firstline=30, lastline=35] {haskell}{code/Heap.hs}

Поскольку длина правой периферии любой вершины в худшем случае
логарифмическая, \lstinline!merge! выполняется за время $O(\log n)$.
\end{frame}

\begin{frame}[fragile]{}
\inputminted[firstline=36, lastline=38] {haskell}{code/Heap.hs}

Поскольку \lstinline!merge! выполняется за время $O(\log n)$, столько
же занимают и \lstinline!insert! с \lstinline!deleteMin!. Очевидно,
что \lstinline!findMin! выполняется за $O(1)$. 
\end{frame}

\begin{frame}[fragile]{}
\begin{exercise}\label{ex:3.2}
  Определите \lstinline!insert! напрямую, а не через обращение к \lstinline!merge!.
\end{exercise}

\begin{exercise}\label{ex:3.3}
  Реализуйте функцию \lstinline!fromList! типа \lstinline!Elem.T list $\to$ Heap!,
  порождающую левоориентированную кучу из неупорядоченного списка
  элементов путем преобразования каждого элемента в одноэлементную
  кучу, а затем слияния получившихся куч, пока не останется
  одна. Вместо того, чтобы сливать кучи проходом слева направо или
  справа налево при помощи \lstinline!foldr! или \lstinline!foldl!,
  слейте кучи за $\lceil \log n \rceil$ проходов, где на каждом
  проходе сливаются пары соседних куч. Покажите, что
  \lstinline!fromList! требует всего $O(n)$ времени.
\end{exercise}
\end{frame}

\begin{frame}[fragile]{}
\begin{exercise}\label{ex:3.4}
  Левоориентированные кучи
  со сдвинутым весом~--- альтернатива левоориентированным кучам, где
  вместо свойства левоориентированности используется свойство
  \term{левоориентированности, сдвинутой по весу}{weight-biased leftist
    property}: размер любого левого поддерева всегда не меньше размера
  соответствующего правого поддерева.
  \begin{enumerate}
    \item Докажите, что правая периферия левоориентированной кучи со
    сдвинутым весом содержит не более $\lfloor \log(n+1) \rfloor$ элементов.
    \item Измените реализацию, чтобы получились
    левоориентированные кучи со сдвинутым весом.
    \item Функция \lstinline!merge! сейчас выполняется в два прохода:
    сверху вниз, с вызовами \lstinline!merge!, и снизу вверх, с
    вызовами вспомогательной функции \lstinline!makeT!. Измените
    \lstinline!merge! для левоориентированных куч со сдвинутым весом
    так, чтобы она работала за один проход сверху вниз.
    \item Каковы преимущества однопроходной версии в
    условиях ленивого вычисления? Параллельного?
  \end{enumerate}
\end{exercise}

\end{frame}

\section{Биномиальные кучи}
\label{sc:3.2}

\begin{frame}[fragile]{}
Биномиальные очереди \cite{Vuillemin1978, Brown1978}, которые мы,
чтобы избежать путаницы с очередями FIFO, будем называть \term{ биномиальными
  кучами}{binomial heaps}~--- ещё одна распространенная реализация
куч. Биномиальные кучи устроены сложнее, чем левоориентированные, и, на
первый взгляд, не возмещают эту сложность никакими
преимуществами. Однако в последующих главах мы увидим, как в различных
вариантах биномиальных куч можно заставить \lstinline!insert! и
\lstinline!merge! выполняться за время $O(1)$.

\end{frame}

\begin{frame}[fragile]{}
Биномиальные кучи строятся из более простых объектов, называемых
биномиальными деревьями. Биномиальные деревья индуктивно определяются
так:
\begin{itemize}
  \item Биномиальное дерево ранга 0 представляет собой одиночный узел.
  \item Биномиальное дерево ранга $r+1$ получается путем
  \term{связывания}{linking} двух биномиальных деревьев ранга $r$, так
  что одно из них становится самым левым потомком второго.
\end{itemize}
Из этого определения видно, что биномиальное дерево ранга $r$ содержит
ровно $2^r$ элементов.  Существует второе, эквивалентное первому,
определение биномиальных деревьев, которым иногда удобнее
пользоваться: биномиальное дерево ранга $r$ представляет собой узел
с $r$ потомками $t_1\ldots t_r$, где каждое $t_i$ является
биномиальным деревом ранга $r-i$.  На Рис.~\ref{fig:3.3} показаны
биномиальные деревья рангов от 0 до 3.
\end{frame}


\begin{frame}[fragile]{}
\begin{figure}[h]
  \centering
  \input{figures/fig.3.3.tex}
  \caption{Биномиальные деревья рангов 0--3.}
  \label{fig:3.3}
\end{figure}

\inputminted[firstline=5, lastline=6] {haskell}{code/BinomialHeap.lhs}

\end{frame}


\begin{frame}[fragile]{}
\inputminted[firstline=5, lastline=6] {haskell}{code/BinomialHeap.lhs}
Каждый список потомков хранится в убывающем порядке рангов, а элементы
хранятся с порядком кучи.  Чтобы сохранять этот порядок, мы всегда
привязываем дерево с большим корнем к дереву с меньшим корнем.
\inputminted[firstline=11, lastline=14] {haskell}{code/BinomialHeap.lhs}
\end{frame}


\begin{frame}[fragile]{}
Определяем биномиальную кучу как 
\begin{itemize}
  \item коллекцию биномиальных деревьев
  \item каждое из которых имеет порядок кучи
  \item никакие два дерева не совпадают по рангу
\end{itemize} 
Например, список деревьев в в порядке возрастания ранга.
\inputminted[firstline=6, lastline=6] {haskell}{code/BinomialHeap.lhs}
\end{frame}


\begin{frame}[fragile]{Биномиальные кучи и числа}
Поскольку каждое биномиальное дерево содержит $2^r$ элементов, и
никакие два дерева по рангу не совпадают, деревья размера $n$ в
точности соответствуют единицам в двоичном представлении
$n$.\\

Например, число $21_{10} = 10101_2$, и поэтому
биномиальная куча размера 21 содержит одно дерево ранга 0, одно ранга
2, и одно ранга 4 (размерами, соответственно, 1, 4 и 16).\\

Заметим, что
так же, как двоичное представление $n$ содержит не более $\lfloor log
(n+1)\rfloor$ единиц, биномиальная куча размера $n$ содержит не более
$\lfloor log(n+1) \rfloor$ деревьев.
\end{frame}


\begin{frame}[fragile]{}
\begin{figure}[h]
  \centering
  \input{figures/fig.3.3_extra.tex}
  \caption{Число $21_{10} = 10101_2$, и поэтому
    биномиальная куча размера 21 содержит одно дерево ранга 0, одно ранга
    2, и одно ранга 4 (размерами, соответственно, 1, 4 и 16).}
\end{figure}

\end{frame}


\begin{frame}[fragile]{\hsinline{insert} и \hsinline{merge} -- аналогично сложению}
% (Мы укрепим эту аналогию в Главе~\ref{ch:9}.). \\

Чтобы внести элемент в кучу,
мы сначала создаем одноэлементное дерево (т.~е., биномиальное дерево
ранга 0), затем поднимаемся по списку существующих деревьев в порядке
возрастания рангов, связывая при этом одноранговые деревья. Каждое
связывание соответствует переносу в двоичной арифметике.

\inputminted[firstline=8,lastline=8] {haskell}{code/BinomialHeap.lhs}
\inputminted[firstline=16,lastline=18] {haskell}{code/BinomialHeap.lhs}

В худшем случае, при вставке в кучу размера $n = 2^k -1$, требуется
$k$ связываний и $O(k) = O(\log n)$ времени.
\end{frame}


\begin{frame}[fragile]{Merge}
При слиянии двух куч мы проходим через оба списка деревьев в порядке
возрастания ранга и связываем по пути деревья равного ранга. Как и
прежде, каждое связывание соответствует переносу в двоичной
арифметике.

\inputminted[firstline=20,lastline=25] {haskell}{code/BinomialHeap.lhs}

\inputminted[firstline=38,lastline=38,gobble=2] {haskell}{code/BinomialHeap.lhs}

\end{frame}

\begin{frame}[fragile]{}
Функции \lstinline!findMin! и \lstinline!deleteMin! вызывают
вспомогательную функцию \lstinline!removeMinTree!, которая находит
дерево с минимальным корнем, исключает его из списка и возвращает как
это дерево, так и список оставшихся деревьев.

\inputminted[firstline=27,lastline=31] {haskell}{code/BinomialHeap.lhs}

Функция \lstinline!findMin! просто возвращает корень найденного дерева

\inputminted[firstline=39,lastline=40,gobble=2] {haskell}{code/BinomialHeap.lhs}

\end{frame}

\begin{frame}[fragile]{}
Функция \lstinline!deleteMin! устроена немного похитрее. \\

 Отбросив
корень найденного дерева, мы ещё должны вернуть его потомков в список
остальных деревьев. Заметим, что список потомков \emph{почти} уже
соответствует определению биномиальной кучи. Это коллекция
биномиальных деревьев с неповторяющимися рангами, но только
отсортирована она не по возрастанию, а по убыванию ранга. Таким
образом, обратив список потомков, мы преобразуем его в биномиальную
кучу, а затем сливаем с оставшимися деревьями.

\inputminted[firstline=42,lastline=43] {haskell}{code/BinomialHeap.lhs}
\end{frame}

\ifanswers
\begin{frame}[fragile]{}
\begin{exercise}\label{ex:3.5}
  Определите \lstinline!findMin! напрямую, без обращения к \lstinline!removeMinTree!.
\end{exercise}

\begin{exercise}\label{ex:3.6}
  Большая часть аннотаций ранга в нашем представлении биномиальных куч
  излишня, потому что мы и так знаем, что дети узла ранга $r$ имеют
  ранги $(r\!-\!1), \ldots, 0$. Таким образом, можно исключить
  поле-аннотацию ранга из узлов, а вместо этого помечать ранг корня
  каждого дерева, т.~е.,
  \begin{minted}{haskell}
  data Tree a = Node  a [Tree]
  type Heap = [(Int, Tree)]
  \end{minted}
  Реализуйте биномиальные кучи в таком представлении.
\end{exercise}
\end{frame}

% Ещё одно упражнение не скопипастьил

\fi

\section{Красно-чёрные деревья}
\label{sc:3.3}

\begin{frame}[fragile]{Красно-чёрные деревья}
В разделе~\ref{sc:2.2} мы описали двоичные деревья поиска. Такие
деревья хорошо ведут себя на случайных или неупорядоченных данных,
однако на упорядоченных данных их производительность резко падает, и
каждая операция может занимать до $O(n)$  времени.  Решение этой
проблемы состоит в том, чтобы каждое дерево поддерживать в
приблизительно сбалансированном состоянии. Тогда каждая операция
выполняется не хуже, чем за время $O(\log n)$. 

 Одним из наиболее
популярных семейств сбалансированных двоичных деревьев поиска являются
красно-чёрные \cite{GuibasSedgewick1978}.
\end{frame}

\begin{frame}[fragile]{}
Красно-чёрное дерево представляет собой двоичное дерево поиска, в
котором каждый узел окрашен либо красным, либо чёрным. Мы добавляем
поле цвета в тип двоичных деревьев поиска из раздела~\ref{sc:2.2}.

\inputminted[firstline=6,lastline=7] {haskell}{code/RedBlackSet.lhs}
Все пустые узлы считаются чёрными, поэтому пустой конструктор
\lstinline!E! в поле цвета не нуждается.

\end{frame}

\begin{frame}[fragile]{}
Мы требуем, чтобы всякое красно-чёрное дерево соблюдало два
инварианта:
\begin{itemize}
  \item \textbf{Инвариант 1.} У красного узла не может быть красного ребёнка.
  \item \textbf{Инвариант 2.} Каждый путь от корня дерева до пустого
  узла содержит одинаковое количество чёрных узлов.
\end{itemize}
Вместе эти два инварианта гарантируют, что самый длинный возможный
путь по красно-чёрному дереву, где красные и чёрные узлы чередуются,
не более чем вдвое длиннее самого короткого, состоящего только из
чёрных узлов.

\ifanswers
\begin{exercise}\label{ex:3.8}
  Докажите, что максимальная глубина узла в красно-чёрном дереве
  размера $n$ не превышает $2 \lfloor \log (n+1) \rfloor$.
\end{exercise}
\fi
\end{frame}

\begin{frame}[fragile]{}
Функция \lstinline!member! для красно-чёрных деревьев не обращает
внимания на цвета. За исключением wildcard в варианте для конструктора
\lstinline!T!, она не отличается от функции \lstinline!member! для
несбалансированных деревьев.
\inputminted[firstline=18,lastline=21] {haskell}{code/RedBlackSet.lhs}
\end{frame}


\begin{frame}[fragile]{}
Функция \lstinline!insert! интереснее: она должна
поддерживать два инварианта балансировки.

\inputminted[firstline=23,lastline=29] {haskell}{code/RedBlackSet.lhs}

Эта функция содержит три существенных изменения по сравнению с \hsinline{insert} для
несбалансированных деревьев поиска. Во-первых, когда мы создаем новый
узел в ветке \hsinline{ins E}, мы сначала окрашиваем его в красный
цвет. Во-вторых, независимо от цвета, возвращаемого \hsinline{ins},
в окончательном результате мы корень окрашиваем чёрным. Наконец, в
ветках \hsinline{x < y} и \hsinline{x > y} мы вызовы конструктора
\hsinline{T} заменяем на обращения к функции
\hsinline{balance}. Функция \hsinline{balance} действует подобно
конструктору \hsinline{T}, но только она переупорядочивает свои
аргументы, чтобы обеспечить выполнение инвариантов баланса.
\end{frame}


\begin{frame}[fragile]{}
\inputminted[firstline=9,lastline=13] {haskell}{code/RedBlackSet.lhs}

Если новый узел окрашен красным, мы сохраняем Инвариант 2, но в
случае, если отец нового узла тоже красный, нарушается Инвариант 1. Мы
временно позволяем существовать одному такому нарушению, и переносим
его снизу вверх по мере перебалансирования. Функция
\lstinline!balance! обнаруживает и исправляет красно-красные нарушения,
когда обрабатывает чёрного родителя красного узла с красным
ребёнком. Такая чёрно-красно-красная цепочка может возникнуть в
четырёх различных конфигурациях, в зависимости от того, левым или
правым ребёнком является каждая из красных вершин. Однако в каждом из
этих случаев решение одно и то же: нужно преобразовать
чёрно-красно-красный путь в красную вершину с двумя чёрными детьми,
как показано на Рис.~\ref{fig:3.5}.
\end{frame}


\begin{frame}[fragile]{}
После балансировки некоторого поддерева красный корень этого поддерева
может оказаться ребёнком ещё одного красного узла. Таким образом,
балансировка продолжается до самого корня дерева. На самом верху
дерева мы можем получить красную вершину с красным ребёнком, но без
чёрного родителя. С этим вариантом мы справляемся, всегда перекрашивая корень
в чёрное.

\end{frame}


\begin{frame}[fragile]{}
\begin{figure}[h]
  \centering
  \input{figures/fig.3.5.tex}
%  \caption{Избавление от красных узлов с красными родителями.}
  \label{fig:3.5}
\end{figure}
\end{frame}

\begin{frame}[fragile]{}
\begin{figure}[h]
  \centering
  \input{figures/fig.3.5_part2.tex}
%  \caption{Избавление от красных узлов с красными родителями.}
  \label{fig:3.5.2}
\end{figure}
\end{frame}

\begin{frame}[fragile]{}
\begin{hint}
  Даже без дополнительных оптимизаций наша реализация сбалансированных
  двоичных деревьев поиска~--- одна из самых быстрых среди
  имеющихся. С оптимизациями вроде описанных в
  Упражнениях~\ref{ex:2.2} и \ref{ex:3.10} она просто летает!
\end{hint}
\end{frame}


\begin{frame}[fragile]{}
\begin{remark}
  Одна из причин, почему наша реализация выглядит настолько проще, чем
  типичное описание красно-чёрных деревьев (напр., Глава~14 в
  книге~\cite{CormenLeisersonRivest1990}), состоит в том, что мы
  используем несколько другие преобразования перебалансировки. В
  императивных реализациях обычно наши четыре проблематичных случая
  разбиваются на восемь, в зависимости от цвета узла, соседствующего с
  красной вершиной с красным ребёнком.  Знание цвета этого узла в
  некоторых случаях позволяет совершить меньше присваиваний, а в
  некоторых других завершить балансировку раньше. Однако в
  функциональной среде мы в любом случае копируем все эти вершины, и
  таким образом, не можем ни сократить число присваиваний, ни
  прекратить копирование раньше времени, так что для использования
  более сложных преобразований нет причины.
\end{remark}

\end{frame}


\begin{frame}[fragile]{}
\begin{exercise}\label{ex:3.9}
  Напишите функцию \hsinline{fromOrdList} типа \hsinline{[a] -> Tree a},
  преобразующую отсортированный список без повторений в красно-чёрное
  дерево. Функция должна выполняться за время $O(n)$.
\end{exercise}

\begin{exercise}\label{ex:3.10}
  Приведенная нами функция \hsinline{balance} производит несколько
  ненужных проверок. Например, когда функция \hsinline{ins}
  рекурсивно вызывается для левого ребёнка, не требуется проверять
  красно-красные нарушения на правом ребёнке.
  \begin{enumerate}
    \item Разбейте \hsinline{balance} на две функции
    \hsinline{lbalance} и \hsinline{rbalance}, которые проверяют,
    соответственно, нарушения инварианта в левом и правом
    ребёнке. Замените обращения к \hsinline{balance} внутри
    \hsinline{ins} на вызовы \hsinline{lbalance} либо \hsinline{rbalance}.
    \item Ту же самую логику можно распространить ещё на шаг и убрать
    одну из проверок для внуков. Перепишите \hsinline{ins} так, чтобы
    она никогда не проверяла цвет узлов, не находящихся на пути поиска.
  \end{enumerate}
\end{exercise}
\end{frame}

\section{Ленивое вычисление}


%\chapter{Основы амортизации}


\section{Методы амортизированного анализа}
\label{sc:5.1}


\begin{frame}[fragile]{}
Реализации с амортизированными
характеристиками производительности часто оказываются проще и быстрее,
чем реализации со сравнимыми жёсткими характеристиками.

К сожалению, простой подход к амортизации, рассматриваемый в этой
главе, конфликтует с идеей устойчивости~--- эти структуры, будучи
используемы как устойчивые, могут быть весьма неэффективны. Однако на
практике многие приложения устойчивости не требуют, и часто для таких
приложений реализации, представленные в этой главе, могут быть
замечательным выбором. В следующей главе мы увидим, как можно
совместить понятия амортизации и устойчивости при помощи ленивого
вычисления.

TODO:
\end{frame}


\begin{frame}[fragile]{}
Понятие амортизации возникает из следующего наблюдения.  Имея
последовательность операций, мы можем интересоваться временем, которое
отнимает вся эта последовательность, однако при этом нам может быть
безразлично время каждой отдельной операции.\\

 Например, имея $n$
операций, мы можем желать, чтобы время всей последовательности было
ограничено показателем $O(n)$, не настаивая, чтобы каждая из этих
операций происходила за время $O(1)$. Нас может устраивать, чтобы
некоторые из операций занимали $O(\log n)$ или даже $O(n)$, при
условии, что общая стоимость всей последовательности будет
$O(n)$. \\

Такая дополнительная степень свободы открывает широкое
пространство возможностей при проектировании, и часто позволяет найти
более простые и быстрые решения, чем варианты с аналогичными жёсткими
ограничениями.

\end{frame}


\begin{frame}[fragile]{}
$$
\sum_{i=1}^m a_i \ge \sum_{i=1}^m t_i
$$
где $a_i$~--- амортизированная стоимость $i$-й операции, $t_i$~--- ее
реальная стоимость, а $m$~--- общее число операций.\\

 Обычно
доказывается несколько более сильный результат: что на любой
промежуточной стадии в последовательности операций общая текущая
амортизированная стоимость является верхней границей для общей текущей
реальной стоимости, т.~е. для любого $j$
$$
\sum_{i=1}^j a_i \ge \sum_{i=1}^j t_i
$$
\end{frame}


\begin{frame}[fragile]{}
\begin{definition}
Разница между общей текущей амортизированной стоимостью
и общей текущей реальной стоимостью называется
\term{текущие накопления}{accumulated savings}. 
\end{definition}
Таким образом, общая
текущая амортизированная стоимость является верхней границей для
общей текущей реальной стоимости тогда и только тогда, когда текущие
накопления неотрицательны.

\end{frame}


\begin{frame}[fragile]{}
Амортизация позволяет некоторым операциям быть дороже, чем их
амортизированная стоимость. Такие операции называются
\term{дорогими}{expensive}. Операции, для которых амортизированная
стоимость превышает реальную, называются
\term{дешевыми}{cheap}. Дорогие операции уменьшают текущие накопления,
а дешевые их увеличивают.\\

 Главное при доказательстве
амортизированных характеристик стоимости~--- показать, что дорогие
операции случаются только тогда, когда текущих накоплений хватает,
чтобы покрыть их дополнительную стоимость.
\end{frame}



\begin{frame}[fragile]{}
\begin{itemize}
  \item \term{Метод банкира}{banker's method} 
      \begin{itemize}
        \item \term{кредит}{credits}
      \end{itemize}
  \item \term{Метод физика}{physicist's method}
      \begin{itemize}
        \item \term{потенциал}{potential}
      \end{itemize}
\end{itemize}



Кредит и потенциал являются лишь средствами анализа; ни
то, ни другое не присутствует в тексте программы (разве что, возможно,
в комментариях).

\end{frame}

\begin{frame}[fragile]{}
 В методе банкира
текущие накопления представляются как \term{кредит}{credits},
привязанный к определенным ячейкам структуры данных. Этот кредит
используется, чтобы расплатиться за будущие операции доступа к этим
ячейкам.  Амортизированная стоимость операции определяется как ее
реальная стоимость плюс размер кредита, выделяемого этой операцией,
минус размер кредита, который она расходует, т.~е.,
$$
a_i = t_i + c_i - \bar{c}_i
$$
где $c_i$~--- размер кредита, выделяемого операцией $i$, а $\bar{c}_i$~---
размер кредита, расходуемого операцией $i$.


\end{frame}

\begin{frame}[fragile]{}
$$
a_i = t_i + c_i - \bar{c}_i
$$
где $c_i$~--- размер кредита, выделяемого операцией $i$, а $\bar{c}_i$~---
размер кредита, расходуемого операцией $i$.\\

 Каждая единица кредита
должна быть выделена, прежде чем израсходована, и нельзя расходовать
кредит дважды. Таким образом, $\sum c_i \ge \sum \bar{c}_i$, а
следовательно, как и требуется, $\sum a_i \ge \sum t_i$.\\

Как правило,
доказательства с использованием метода банкира определяют
\term{инвариант кредита}{credit invariant}, регулирующий распределение
кредита так, чтобы при всякой дорогой операции достаточное его
количество было выделено в нужных ячейках структуры для покрытия
стоимости операции.
\end{frame}


\begin{frame}[fragile]{}
1
\end{frame}

\begin{frame}[fragile]{Метод физика}
Определяется функция $\Phi$, отображающая всякий
объект $d$ на действительное число, называемое его
\term{потенциалом}{potential}.  Потенциал обычно выбирается так, чтобы
изначально равняться нулю и оставаться неотрицательным. В таком случае
потенциал представляет нижнюю границу  текущих накоплений.\\

Пусть объект $d_i$ будет результатом операции $i$ и аргументом
операции $i+1$. Тогда амортизированная стоимость операции $i$
определяется как сумма реальной стоимости и изменения потенциалов между
$d_{i-1}$ и $d_i$, т.~е.,
$$
a_i = t_i + \Phi(d_i) - \Phi(d_{i-1})
$$
текущих накоплений.


\end{frame}


\begin{frame}[fragile]{}
$$
a_i = t_i + \Phi(d_i) - \Phi(d_{i-1})
$$
Текущая реальная стоимость последовательности операций равна
$$
\begin{array}{rcl}
\sum_{i=1}^j t_i & = & \sum_{i=0}^j (a_i + \Phi(d_{i-1}) - \Phi(d_i))\\
\\
& = & \sum_{i=1}^j a_i + \sum_{i=1}^j (\Phi(d_{i-1}) - \Phi(d_i)) \\
\\
& = & \sum_{i=1}^j a_i + \Phi(d_0) - \Phi(d_j)
\end{array}
$$

Если $\Phi$ выбран таким образом, что
$\Phi(d_0)$ равен нулю, а $\Phi(d_j)$ неотрицателен, мы имеем
$\Phi(d_j) \ge \Phi(d_0)$, так что, как и требуется, текущая общая
амортизированная стоимость является верхней границей для текущей общей
реальной стоимости.

\end{frame}

\begin{comment}
\begin{remark}
Такое описание метода физика несколько упрощает
картину. Часто при анализе оказывается трудно втиснуть реальное
положение дел в указанные рамки. Например, что делать с функциями,
которые порождают или возвращают более одного объекта? Однако даже
упрощенное описание достаточно для демонстрации основных идей.
\end{remark}

\end{comment}

\section{Очереди}
\label{sc:5.2}


\begin{frame}[fragile]{}

\begin{minipage}{.4\textwidth}
  \inputminted[firstline=5,lastline=11] {haskell}{code/Queue.lhs}
\end{minipage}
\begin{minipage}{.55\textwidth}
  Самая распространенная чисто функциональная реализация очередей
  представляет собой пару списков, \hsinline{f} и \hsinline{r}, где
  \hsinline{f} содержит головные элементы очереди в правильном порядке,
  а \hsinline{r} состоит из хвостовых элементов в обратном порядке.\\
  
  Например, очередь, содержащая целые числа 1\ldots 6, может быть
  представлена списками \hsinline{f=[1,2,3]} и
  \hsinline{r=[6,5,4]}. Это представление можно описать следующим
  типом:
  \begin{minted}{haskell}
  data Queue a = Queue [a] [a]
  \end{minted}
  
\end{minipage}
\end{frame}


\begin{frame}[fragile]{}
В этом представлении голова очереди~--- первый элемент \hsinline{f},
так что функции \hsinline{head} и \hsinline{tail}
возвращают и отбрасывают этот элемент, соответственно.
\begin{minted}{haskell}
head (x : f, r) = x
tail (x : f, r) = f
\end{minted}
Подобным образом, хвостом очереди является первый элемент
\hsinline{r}, так что \hsinline{snoc} добавляет к \hsinline{r}
новый.
\begin{minted}{haskell}
snoc (f,r) x = (f, x : r)
\end{minted}

\end{frame}


\begin{frame}[fragile]{}
Элементы добавляются к \hsinline{r} и убираются из \hsinline{f}, так
что они должны как-то переезжать из одного списка в другой. Этот
переезд осуществляется путем обращения \hsinline{r} и установки его
на место \hsinline{f} всякий раз, когда в противном случае
\hsinline{f} оказался бы пустым.\\

 Одновременно \hsinline{r}
устанавливается в \hsinline{[]}. Наша цель~--- поддерживать
инвариант, что список \hsinline{f} может быть пустым только в том
случае, когда список \hsinline{r} также пуст (т.~е., пуста вся
очередь). \\

Заметим, что если бы \hsinline{f} был пустым при непустом
\hsinline{r}, то первый элемент очереди находился бы в конце
\hsinline{r}, и доступ к нему занимал бы $O(n)$ времени. Поддерживая
инвариант, мы гарантируем, что функция \hsinline{head} всегда может
найти голову очереди за $O(1)$ времени.

\end{frame}


\begin{frame}[fragile]{}
\begin{minted}{haskell}
snoc (([], _), x) = ([x], [])
snoc (( f, r), x) = (f,  x :: r)
tail ([x], r) = (rev r, [])
tail (x:f, r) = (f, r)
\end{minted}

Заметим, что в первой ветке \hsinline{snoc} используется
wildcard. В этом случае поле \hsinline{r} проверять не нужно,
поскольку из инварианта мы знаем, что если список \hsinline{f} равен
\hsinline{[]}, то \hsinline{r} также пуст.

\end{frame}


\begin{frame}[fragile]{}
Чуть более изящный способ записать эти функции~--- вынести те части
\hsinline{snoc} и \hsinline{tail}, которые поддерживают инвариант, в
отдельную функцию \hsinline{checkf}. Она заменяет \hsinline{f} на
\hsinline{rev r}, если \hsinline{f} пуст, а в противном случае
ничего не делает.

\inputminted[firstline=10,lastline=15] {haskell}{code/NaiveQueue.hs}

Функции
\hsinline{snoc} и \hsinline{head} всегда завершаются за время
$O(1)$, но \hsinline{tail} в худшем случае отнимает $O(n)$
времени. 

Однако, используя либо метод банкира, либо метод физика, мы
можем показать, что как \hsinline{snoc}, так и \hsinline{tail}
занимают амортизированное время $O(1)$.

\end{frame}


\begin{frame}[fragile]{Чисто функциональная очередь и метод банкира}

Инвариант: каждый элемент в
хвостовом списке связан с одной единицей кредита. \\

Каждый вызов
\hsinline{snoc} для непустой очереди занимает один реальный шаг и
выделяет одну единицу кредита для элемента хвостового списка; таким
образом, общая амортизированная стоимость равна двум. \\

Вызов
\hsinline{tail}, не обращающий хвостовой список, занимает один шаг,
не выделяет и не тратит никакого кредита, и, таким образом, имеет
амортизированную стоимость 1. \\

Наконец, вызов \hsinline{tail},
обращающий хвостовой список, занимает $m+1$ реальный шаг, где $m$~---
длина хвостового списка, и тратит $m$ единиц кредита, содержащиеся в
этом списке, так что амортизированная стоимость получается $m + 1 - m
= 1$.

\end{frame}


\begin{frame}[fragile]{Чисто функциональная очередь и метод физика}
В методе физика мы определяем функцию потенциала $\Phi$ как длину
хвостового списка. \\

Тогда всякий \hsinline{snoc} к непустой очереди
занимает один реальный шаг и увеличивает потенциал на единицу, так что
амортизированная стоимость равна двум. \\

Вызов \hsinline{tail} без
обращения хвостовой очереди занимает один реальный шаг и не изменяет
потенциал, так что амортизированная стоимость равна одному.\\

 Наконец,
вызов \hsinline{tail} с обращением очереди занимает $m+1$ реальный
шаг, но при этом устанавливает хвостовой список равным \hsinline{[]},
уменьшая таким образом потенциал на $m$, так что амортизированная
стоимость равна $m + 1 - m = 1$.

\end{frame}


\begin{frame}[fragile]{}
\begin{hint}
  Эта реализация очередей идеальна в приложениях, где не требуется
  устойчивости и где приемлемы амортизированные показатели
  производительности.
\end{hint}

\end{frame}

\ifanswers
\begin{frame}[fragile]{}
\begin{exercise}\label{ex:5.1}
  \textbf{Хогерворд \cite{Hoogerwoord1992}.}  Идея этих очередей легко
  может быть расширена на абстракцию \term{двусторонней очереди}{double-ended
    queue}, или \term{дека}{deque}, где чтение и запись разрешены с
  обоих концов очереди (см. Рис.~\ref{fig:5.3}). Инвариант делается
  симметричным относительно \lstinline!f! и \lstinline!r!: если
  очередь содержит более одного элемента, оба списка должны быть
  непустыми. Когда один из списков становится пустым, мы делим другой
  пополам и одну из половин обращаем.
  
  \begin{enumerate}
    \item Реализуйте эту версию деков.
    \item Докажите, что каждая операция занимает $O(1)$ амортизированного
    времени, используя функцию потенциала $\Phi(f,r) = abs(|f| -
    |r|)$, где $abs$~--- функция модуля.
  \end{enumerate}
\end{exercise}
\end{frame}
\fi

\section{Биномиальные кучи}
\label{sc:5.3}


\begin{frame}[fragile]{}
В Разделе~\ref{sc:3.2} мы показали, что вставка в биномиальную кучу
проходит в худшем случае за время $O(\log n)$. Здесь мы доказываем,
что на самом деле амортизированное ограничение на время вставки
составляет $O(1)$.\\

Метод физика. Потенциал биномиальной кучи -- число деревьев в ней. 

Заметим, что это число равно количеству
единиц в двоичном представлении $n$, числа элементов в куче.  Вызов
\hsinline{insert} занимает $k+1$ шаг, где $k$~--- число обращений к
\hsinline{link}. Если изначально в куче было $t$ деревьев, то после
вставки окажется $t - k + 1$ деревьев. Таким образом, изменение
потенциала составляет $(t - k + 1) - t = 1 - k$, а амортизированная
стоимость вставки $(k + 1) - (1 - k) = 2$.\\

\begin{exercise}\label{ex:5.2}
  Повторите доказательство с использованием метода банкира.
\end{exercise}

\end{frame}


\begin{frame}[fragile]{}
Для полноты картины нам нужно показать, что амортизированная стоимость
операций \hsinline{merge} и \hsinline{deleteMin} по-прежнему
составляет $O(\log n)$. \hsinline{deleteMin} не доставляет здесь
никаких трудностей, но в случае \hsinline{merge} требуется небольшое
расширение метода физика. \\

До сих пор мы определяли амортизированную
стоимость операции как
$$
a = t + \Phi(d_{\mbox{\textit{вых}}}) - \Phi(d_{\mbox{\textit{вх}}})
$$
где $d_{\mbox{\textit{вх}}}$~--- структура на входе операции, а $d_{\mbox{\textit{вых}}}$~---
структура на выходе. Однако если операция принимает либо возвращает
более одного объекта, это определение требуется обобщить до
$$
a = t + \sum_{d \in \mbox{\textit{Вых}}} \Phi(d) - \sum_{d \in \mbox{\textit{Вх}}} \Phi(d)
$$
где $\mbox{\textit{Вх}}$~--- множество входов, а $\mbox{\textit{Вых}}$~--- множество выходов. В этом
правиле мы рассматриваем только входы и выходы анализируемого типа.
\end{frame}

\ifanswers
\begin{frame}[fragile]{}
\begin{exercise}\label{ex:5.3}
  Докажите, что амортизированная стоимость операций \hsinline{merge}
  и \hsinline{deleteMin} по-прежнему составляет $O(\log n)$.
\end{exercise}
\end{frame}
\fi


\section{Расширяющиеся кучи}
\label{sc:5.4}

\begin{frame}[fragile]{}
\term{Расширяющиеся деревья}{splay trees} \cite{SleatorTarjan1985}~--- возможно, самая известная
и успешно применяемая амортизированная структура данных.\\

 Расширяющиеся
деревья являются ближайшими родственниками двоичных сбалансированных
деревьев поиска, но они не хранят никакую информацию о балансе
явно. \\

Вместо этого каждая операция перестраивает дерево при помощи
некоторых простых преобразований, которые имеют тенденцию увеличивать
сбалансированность. Несмотря на то, что каждая конкретная операция
может занимать до $O(n)$ времени, амортизированная стоимость ее, как
мы покажем, не превышает $O(\log n)$.
\end{frame}


\begin{frame}[fragile]{}
Важное различие между расширяющимися и сбалансированными
двоичными деревьями поиска вроде красно-чёрных деревьев из
Раздела~\ref{sc:3.3} состоит в том, что расширяющиеся деревья
перестраиваются даже во время запросов (таких, как \hsinline{member}),
а не только во время обновлений (таких, как \hsinline{insert}). \\

Это
свойство мешает использованию расширяющихся деревьев для реализации
абстракций вроде множеств или конечных отображений в чисто
функциональном окружении, поскольку приходилось бы возвращать в
запросе новое дерево наряду с ответом на запрос\footnote{%
  В принципе можно было бы хранить корень расширяющегося дерева в
  ссылочной ячейке и обновлять значение по ссылке при каждом запросе, но
  такое решение не является чисто функциональным.
}
\end{frame}


\begin{frame}[fragile]{}
Представление расширяющихся деревьев идентично представлению
несбалансированных двоичных деревьев поиска.
\inputminted[firstline=5,lastline=5] {haskell}{code/SplayHeap.lhs}


Однако в отличие от несбалансированных двоичных деревьев поиска из
Раздела~\ref{sc:2.2}, мы позволяем дереву содержать повторяющиеся
элементы. Эта разница не является фундаментальным различием расширяющихся
деревьев и несбалансированных двоичных деревьев поиска; она просто
отражает отличие абстракции множества от абстракции кучи.

\end{frame}


\begin{frame}[fragile]{Реализация \hsinline{insert} }
Разобьем существующее дерево на два поддерева, чтобы одно содержало все
элементы, меньше или равные новому, а второе все элементы, большие
нового. Затем породим новый узел из нового элемента и двух этих
поддеревьев. В отличие от вставки в обыкновенное двоичное дерево
поиска, эта процедура добавляет элемент как корень дерева, а не как
новый лист.

\begin{minted}{haskell}
insert x t = T (smaller (x, t))  x (bigger (x, t))
\end{minted}


где \hsinline{smaller} выделяет дерево из элементов, меньше или равных
\hsinline{x}, а \hsinline{bigger} -- больших
\hsinline{x}. 

\end{frame}


\begin{frame}[fragile]{Наивная реализация \hsinline{bigger}}
По аналогии с фазой разделения быстрой сортировки,
назовем новый элемент \term{границей}{pivot}.

Можно наивно реализовать \hsinline{bigger} как

\begin{minted}{haskell}
bigger pivot E = E
bigger pivot (T a x b) =
  if x <= pivot 
  then bigger pivot b
  else T (bigger pivot a) x b
\end{minted}
однако при таком решении не делается никакой попытки перестроить
дерево, добиваясь лучшего баланса.
%\begin{minted}{haskell}
%insert x t = T (smaller (x, t))  x (bigger (x, t))
%\end{minted}
\end{frame}

\begin{frame}[fragile]{Правильная реализация \hsinline{bigger} }
\begin{minted}{haskell}
bigger pivot E = E
bigger pivot (T a x b) =
  if x <= pivot 
  then bigger (pivot, b)
  else case a of
    E             -> T (E, x, b)
    T (a1, y, a2) ->
        if y <= pivot 
        then T (bigger pivot a2) x b)
        else T (bigger pivot a1) y (T a2 x b)

\end{minted}
\end{frame}

\begin{frame}[fragile]{}
1
\end{frame}

\begin{frame}[fragile]{}
1
\end{frame}

\begin{frame}[fragile]{}
1
\end{frame}

\begin{frame}[fragile]{}
1
\end{frame}

\begin{frame}[fragile]{}
1
\end{frame}

\begin{frame}[fragile]{}
1
\end{frame}


\begin{frame}[fragile]{}
1
\end{frame}



% \begin{frame}[allowframebreaks]
%   \frametitle<presentation>{Ссылки}
%   \begin{thebibliography}{10}
%   \bibitem{paper}
%     \href{http://conal.net/papers/compiling-to-categories/compiling-to-categories.pdf}{paper}
%     \newblock {\em Conal Elliot }    
%   \bibitem{conal}
%     Slides
%     \newblock {\em Conal Elliot }
%     \newblock \href{http://conal.net/talks/compiling-to-categories.pdf}{ссылка}
%   \bibitem{video}    
%     \href{http://podcasts.ox.ac.uk/compiling-categories}{ICFP 2017 video}
%     \newblock {\em Conal Elliot }
%   \bibitem{}
%     \href{https://github.com/conal/concat}{Project repo}
%   \end{thebibliography}
% \end{frame}

\end{document}
